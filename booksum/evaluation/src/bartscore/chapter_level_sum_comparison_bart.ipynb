{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import math\n",
    "import statistics\n",
    "from bart_score import BARTScorer\n",
    "\n",
    "def get_human_summary(summary_path):\n",
    "    try:\n",
    "        with open(\"../../../scripts/\" + summary_path, encoding='utf-8') as f:\n",
    "            summary_json = json.load(f)\n",
    "            return summary_json[\"summary\"]\n",
    "    except Exception as e:\n",
    "        print(\"Failed to read summary file: {}\".format(e))\n",
    "        return None\n",
    "\n",
    "def calculate_F1():\n",
    "    summaries_count = 0\n",
    "    data = []\n",
    "    used_files = []\n",
    "    unique_books = set()\n",
    "    unique_used_books = set()\n",
    "\n",
    "    human_summaries = dict()\n",
    "    #f = open(pathlib.Path(\"../../booksum/alignments/chapter-level-summary-alignments/chapter_summary_aligned_all_split.jsonl\"),\n",
    "\n",
    "    stopcount = 0\n",
    "    \n",
    "    f = open(pathlib.Path(\"../../../alignments/chapter-level-summary-alignments/chapter_summary_aligned_train_split.jsonl\"),\n",
    "             encoding='utf-8')\n",
    "\n",
    "    for line in f:\n",
    "        content = json.loads(line)\n",
    "        if content['source'] == 'pinkmonkey':\n",
    "            continue\n",
    "        text = get_human_summary(content['summary_path'])\n",
    "        if text is not None:\n",
    "            try:\n",
    "                human_summaries[content['summary_path']] = {\n",
    "                    \"chapter_title\": content['book_id'],\n",
    "                    \"source\": content['source'],\n",
    "                    \"summary_text\": text,\n",
    "                }\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    \n",
    "    print(\"Evaluating {} summary documents...\".format(len(human_summaries)))\n",
    "    print(\"Please send help!\",type(human_summaries.items()))\n",
    "    for summary_path, summary in human_summaries.items():\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "        # Get all related summary documents.\n",
    "        unique_books.add(summary['chapter_title'])\n",
    "        # Special case for Around the World in Eighty (80) Days\n",
    "        if summary['chapter_title'] == \"Around the World in Eighty Days\":\n",
    "            related_summaries = list(filter(\n",
    "                lambda curr_summary: curr_summary['chapter_title'] == 'Around the World in 80 Days', human_summaries.values()))\n",
    "\n",
    "        elif summary['chapter_title'] == \"Around the World in 80 Days\":\n",
    "            related_summaries = list(filter(\n",
    "                lambda curr_summary: curr_summary['chapter_title'] == 'Around the World in Eighty Days', human_summaries.values()))\n",
    "\n",
    "        else:\n",
    "            related_summaries = list(filter(lambda curr_summary: curr_summary['chapter_title'] == summary[\n",
    "                                     'chapter_title'] and curr_summary['source'] != summary['source'], human_summaries.values()))\n",
    "        # Remember which files have been used.\n",
    "        used_files.extend(related_summaries)\n",
    "        # print(summary['chapter_title'], summary['source'])\n",
    "        # print(related_summaries)\n",
    "\n",
    "        # if there are no related summary documents, then just print.\n",
    "        if len(related_summaries) == 0:\n",
    "            print(\"No related summary documents were found for {}.\".format(\n",
    "                summary['chapter_title']))\n",
    "            continue\n",
    "\n",
    "        # # Run the ROUGE command using the current summary as the reference and the related summaries as hypotheses.\n",
    "        # # Print the scores and save them.\n",
    "        related_summary_texts = [curr_summary['summary_text']\n",
    "                                 for curr_summary in related_summaries]\n",
    "\n",
    "        print(\"-------\")\n",
    "\n",
    "        ref_sents = tokenize.sent_tokenize(summary['summary_text'])\n",
    "\n",
    "        human_summary_groups = []\n",
    "\n",
    "        for curr in related_summary_texts:\n",
    "            human_summary_groups.append(tokenize.sent_tokenize(curr))\n",
    "\n",
    "        \n",
    "        summary_scores = []\n",
    "\n",
    "        #print(\"HSUM:\", human_summary_groups)\n",
    "        for i, summary in enumerate(human_summary_groups):\n",
    "            for j, sent in enumerate(summary):\n",
    "                if len(sent) == 1:\n",
    "                    #print(\"human_summary_groups[i].get(sent)\" ,human_summary_groups[i].get(sent))\n",
    "                    human_summary_groups[i].remove(sent)\n",
    "        #print(\"--------\")\n",
    "        print(\"HSUM Cleaned:\", human_summary_groups)\n",
    "\n",
    "        bart_scorer = BARTScorer(device='cuda:0', checkpoint='facebook/bart-large-cnn')\n",
    "\n",
    "        for i, human_summary in enumerate(human_summary_groups):\n",
    "            scentence_scores = []\n",
    "\n",
    "            for ref_sent in ref_sents:\n",
    "                best_score = -math.inf\n",
    "\n",
    "                for hyp_sent in human_summary:\n",
    "                    #print(\"ref: \", ref_sent)\n",
    "                    #print(\"hyp: \", hyp_sent)\n",
    "                    curr_score = bart_scorer.score([ref_sent], [hyp_sent]) #place inside array or else bart does it per word instead of scentence to scentence\n",
    "                    #print(curr_score)\n",
    "                    assert len(curr_score) == 1\n",
    "                    if curr_score[0] > best_score:\n",
    "                        best_score = curr_score[0]\n",
    "\n",
    "                scentence_scores.append(best_score)\n",
    "\n",
    "            mean_summary_score = statistics.mean(scentence_scores)\n",
    "            summary_scores.append(mean_summary_score)\n",
    "\n",
    "        print(\"Higest summary score: \", max(summary_scores))\n",
    "        mean_sum_score = statistics.mean(summary_scores)\n",
    "        print(\"Mean summary score: \", mean_sum_score)\n",
    "\n",
    "\n",
    "        data.append([mean_sum_score, summary['chapter_title'], summary['source']])\n",
    "        unique_used_books.add(summary['chapter_title'])\n",
    "        summaries_count += 1\n",
    "\n",
    "        stopcount += 1\n",
    "\n",
    "        if stopcount >= 1:\n",
    "            break\n",
    "\n",
    "\n",
    "    return data, summaries_count, unique_books, unique_used_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "data, summaries_count, unique_chapters, unique_used_chapters = calculate_F1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique chapters covered: {}\".format(len(unique_chapters)))\n",
    "print(\"Unique chapters used: {}\".format(len(unique_used_chapters)))\n",
    "BART_list = [data_item[0] for data_item in data]\n",
    "BART_mean = sum(BART_list) / len(BART_list)\n",
    "print(\"Mean BART: {}\".format(BART_mean))\n",
    "print()\n",
    "\n",
    "# # Comment these out to avoid saving the csv files.\n",
    "df = pd.DataFrame(data, columns=[\"BARTo\", \"chapter-title\", \"source\"])\n",
    "# Save file.\n",
    "df.to_csv(\"../../csv_results/booksum_summaries/chapter-level-sum-comparison-results-test-bart.csv\")\n",
    "\n",
    "del()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('bartclone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbdd4d0d8d6fd6f45b98016386f030380d31cdec56d4436404200754b27f1ef8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
